[{"title":"pip与conda换源","path":"2022/02/14/e12fbaadf62f/","text":"condalinux修改~/.condarc 123456channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ssl_verify: true windowswindows用户需先执行conda config --set show_channel_urls yes，生成.condarc文件，再进行修改 pip阿里云 http://mirrors.aliyun.com/pypi/simple/中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/豆瓣(douban) http://pypi.douban.com/simple/清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ linux临时换源： pip后加-i，指定pip源 永久换源： 修改~/.pip/pip.conf 12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple windows在user目录新建pip目录，路径为C:\\User\\xx\\pip\\pip.ini 1234[global]timeout = 6000index-url = https://pypi.tuna.tsinghua.edu.cn/simpletrusted-host = pypi.tuna.tsinghua.edu.cn"},{"title":"健身小白的入门","path":"2022/02/08/cb9e10900f12/","text":"逢年过节胖三斤，真不是说着玩的。终于下定决心要健身了。看着健身房一堆器材着实发愁，不知道从何下手。在这里稍微汇总一下查阅的资料。当然，最重要的还是坚持，坚持，坚持！ 首先健身房一般分个区域。有氧区、固定器械区、自由器械区、多功能区。小白力量训练的话主要从固定器械区入手。 主要练习方式有三阶段或五阶段，三阶段包括：，五阶段包括：胸、肩、背、腹、腿。每次训练选择2-3个肌肉群进行训练。其中腹肌恢复较快，可连续训练。 常见器械胸肌肉群肩肌肉群背肌肉群腹肌肉群腿肌肉群计划表 星期一 星期三 星期五 胸部： 背部： 腿部： 腹部： 肩臂： 腹部： 注意事项渐进负荷 先加重量 加不了了加个数 加不了了加组数 运动前后一定要拉伸 有氧运动：肌肉、关节、韧带热身——有氧运动（跑步、跳绳、骑单车、椭圆机、登山机、单车）——静态放松肌肉拉伸 无氧运动：目标肌肉的热身——复合动作+孤立动作——组间休息——有氧运动——静态放松肌肉拉伸 拉伸"},{"title":"mmdetection的一些小坑","path":"2022/01/23/a04a392a8742/","text":"记录一下使用mmdetection中遇到的一些坑，方便查阅。 安装pip install mmcv-full==1.3.9 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html pip install mmcv-full==1.3.9 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html 修改完后，需要重新编译（python setup.py install) pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/{torch_version}/index.html pip install mmcv-full==1.3.3 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html pip install -r requirements/build.txtpython setup.py develop 修改数据集为coco格式目录格式： 12345678910mmdetection├── mmdet├── tools├── configs├── data│ ├── coco│ │ ├── annotations│ │ ├── train2017│ │ ├── val2017│ │ ├── test2017 修改相关文件： (4条消息) mmdetection自定义数据集进行训练_xiangxianghehe的博客-CSDN博客_mmdetection 训练数据集 常用命令测试与训练python tools/test.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py checkpoints/epoch_2.pth –show python tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py python tools/test.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py checkpoints/{model}/latest.pth –out results/{model}/results.pkl –show-dir results/ 1python tools/test.py configs/fcos/fcos_r50_caffe_fpn_gn-head_1x_coco.py checkpoints/latest.pth --out results/fcos_r50_caffe_fpn_gn-head_1x_coco/results.pkl --show-dir results/ train参数This tool accepts several optional arguments, including: --no-validate (not suggested): Disable evaluation during training. --work-dir $&#123;WORK_DIR&#125;: Override the working directory. --resume-from $&#123;CHECKPOINT_FILE&#125;: Resume from a previous checkpoint file. --options &#39;Key=value&#39;: Overrides other settings in the used config. 查看configpython tools/misc/print_config.py configs/zr/zr_fcos_r50_caffe_fpn_gn-head_1x_coco.py 学习率配置X：我的一个batchsize输入图像数量Y：mmdetction一个batchsize输入图像数量Z：默认学习率 新的学习率= （X/Y）x Z如：X：1GPU+2img/GPU=2张MMdet默认是8GPU*2img/GPU=16张MMdet默认学习率=0.02新的学习率=0.0025 为了克服数据量多的问题，我们会选择将数据分成几个部分，即batch，进行训练，从而使得每个批次的数据量是可以负载的。将这些batch的数据逐一送入计算训练，更新神经网络的权值，使得网络收敛。 一个epoch指代所有的数据送入网络中完成一次前向计算及反向传播的过程。由于一个epoch常常太大，计算机无法负荷，我们会将它分成几个较小的batches。 所谓Batch就是每次送入网络中训练的一部分数据，而Batch Size就是每个batch中训练样本的数量 所谓iterations就是完成一次epoch所需的batch个数。 简单一句话说就是，我们有2000个数据，分成4个batch，那么batch size就是500。运行所有的数据进行训练，完成1个epoch，需要进行4次iterations。 TOOLSLog Analysistools/analysis_tools/analyze_logs.py plots loss/mAP curves given a training log file. Run pip install seaborn first to install the dependency. 1python tools/analysis_tools/analyze_logs.py plot_curve [--keys $&#123;KEYS&#125;] [--title $&#123;TITLE&#125;] [--legend $&#123;LEGEND&#125;] [--backend $&#123;BACKEND&#125;] [--style $&#123;STYLE&#125;] [--out $&#123;OUT_FILE&#125;] ```python tools/analysis_tools/analyze_logs.py plot_curve work_dirs/faster_rcnn_r50_fpn_1x_coco/20210809_105106.log.json –keys loss_cls –legend loss_cls123- ``` python tools/analysis_tools/analyze_logs.py plot_curve work_dirs/faster_rcnn_r50_fpn_1x_coco/20210809_105106.log.json --keys bbox_mAP --legend bbox_mAP Result Analysistools/analysis_tools/analyze_results.py calculates single image mAP and saves or shows the topk images with the highest and lowest scores based on prediction results. Usage: 123456789python tools/analysis_tools/analyze_results.py \\ $&#123;CONFIG&#125; \\ $&#123;PREDICTION_PATH&#125; \\ $&#123;SHOW_DIR&#125; \\ [--show] \\ [--wait-time $&#123;WAIT_TIME&#125;] \\ [--topk $&#123;TOPK&#125;] \\ [--show-score-thr $&#123;SHOW_SCORE_THR&#125;] \\ [--cfg-options $&#123;CFG_OPTIONS&#125;] Description of all arguments: config : The path of a model config file. prediction_path: Output result file in pickle format from tools/test.py show_dir: Directory where painted GT and detection images will be saved --show：Determines whether to show painted images, If not specified, it will be set to False --wait-time: The interval of show (s), 0 is block --topk: The number of saved images that have the highest and lowest topk scores after sorting. If not specified, it will be set to 20. --show-score-thr: Show score threshold. If not specified, it will be set to 0. --cfg-options: If specified, the key-value pair optional cfg will be merged into config file Examples: Assume that you have got result file in pickle format from tools/test.py in the path ‘./result.pkl’. Test Faster R-CNN and visualize the results, save images to the directory results/ 1python tools/analysis_tools/analyze_results.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py result.pkl results --show Test Faster R-CNN and specified topk to 50, save images to the directory results/ 12345python tools/analysis_tools/analyze_results.py \\ configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py \\ result.pkl \\ results \\ --topk 50 If you want to filter the low score prediction results, you can specify the show-score-thr parameter 12345python tools/analysis_tools/analyze_results.py \\ configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py \\ result.pkl \\ results \\ --show-score-thr 0.3 1python tools/analysis_tools/eval_metric.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py result.pkl"},{"title":"博客施工记录","path":"2022/01/18/ebc99e4d4103/","text":"记录一下hexo的施工过程。主要参考K大的这篇基于 Hexo 的全自动博客构建部署系统 ，我再稍微补充一些自己遇到的坑。 施工进度 smms上传限制5M图片，如果图片大于5M需要对图片进行压缩 action缓存，构建加速 dns负载均衡（暂时没有第二个服务器） 评论模块 归档页 新建文章在hexo根目录下，终端输入hexo new [layout] [title] Layout Path post (default) source/_posts draft source/_drafts page source 草稿发布hexo publish [title] md图床问题Markdown使用图床很方便，我现在用的图床是SMMS，暂时没多大问题，但前期做好备份还是有备无患。因此，最好的解决方案是先将图片保存到本地目录，写完push至github后，结合Action自动读取md源文件，并将图片链接转换为图床链接，再完成hexo渲染。 python转换代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import argparseimport osimport argparseimport reimport requestsimport jsondef smms_upload(img): # 判断图片是否大于5M with open(img, &#x27;rb&#x27;) as img_file: if os.path.getsize(img) &lt; 5 * 1024 * 1024: try: smms_url = &#x27;https://sm.ms/api/v2/upload&#x27; response = requests.post( smms_url, files=&#123;&#x27;smfile&#x27;: img_file, &#x27;format&#x27;: &#x27;json&#x27;&#125;, headers=&#123;&#x27;Authorization&#x27;: smms_token&#125; ) print(&quot;upload finish&quot;) img_new_url = json.loads(response.text) cloud_path = img_new_url[&#x27;data&#x27;][&#x27;url&#x27;] return cloud_path except BaseException as err: print(f&quot;error in upload to smms:&#123;err&#125;&quot;) else: print(&#x27;err in upload, image size is more than 5M&#x27;) return Nonedef convert2url(file_path): with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f: lines = f.readlines() outs = [] for line in lines: if re.search(&#x27;\\!\\[.*\\)&#x27;, line) is not None: images_offline = re.findall(&#x27;\\!\\[.*\\)&#x27;, line) # 找到每段中所有的图片本地链接 for item in images_offline: # 对每个链接进行替换 img_path = re.search(&#x27;(?&lt;=\\()(.+?)(?=\\))&#x27;, item).group() # 判断图片路径是否为网络路径 if re.search(&#x27;[a-zA-z]+://[^\\s]*&#x27;, img_path) is None: img_file = os.path.join(path_md, img_path) images_online = smms_upload(img_file) if images_online is not None: line = line.replace(img_path, images_online) outs.append(line) else: outs.append(line) with open(file_path, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f: f.writelines(outs)if __name__ == &quot;__main__&quot;: ap = argparse.ArgumentParser() ap.add_argument(&quot;-p&quot;, &quot;--path&quot;, help=&quot;the path of your post file&quot;) ap.add_argument(&quot;-t&quot;, &quot;--token&quot;, help=&quot;the token of your smms count&quot;) args = ap.parse_args() path_md = args.path smms_token = args.token md_list = os.listdir(path_md) md_list = [item for item in md_list if item.endswith(&#x27;md&#x27;)] for item in md_list: file_path = os.path.join(path_md, item) convert2url(file_path) Github Action自动部署每次部署在本地hexo g -d，只是在本地构建文件再提交，github只充当了一个静态服务器的作用，没有起到git的作用，因此使用Github Action可以实现自动化部署，且可以实现图床链接的替换。 在.github目录下新建文件夹.workflows，再新建文件deployment.yml，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950name: Hexo Auto-Deployon: [push]jobs: repalce_image: name: md images replace runs-on: ubuntu-latest steps: - name: 1. git checkout uses: actions/checkout@v2.4.0 - name: 2. setup python uses: actions/setup-python@v2.3.1 with: python-version: &quot;3.8.x&quot; architecture: &quot;x64&quot; - name: 3. setup and run run: | pip install requests sudo apt install tree tree source/ python convert_img2url.py -p source/_posts -t &quot;$&#123;&#123; secrets.SMMS_TOKEN &#125;&#125;&quot; - name: 4. install hexo... run: | npm install hexo-cli -g npm install npm list --depth 0 - name: 5. hexo generate run: | hexo clean hexo g - name: 6. hexo deploy ... run: | mkdir -p ~/.ssh/ echo &quot;$&#123;&#123; secrets.ACCESS_TOKEN &#125;&#125;&quot; &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts git config --global user.name &quot;zrtty1998&quot; git config --global user.email &quot;zrtty1998@gmail.com&quot; git config --global core.quotepath false hexo d 负载均衡HTTP重定向HTTP重定向通过一台服务器根据用户的HTTP请求计算出真实服务器地址，将该地址返回到重定向响应中返回给用户。这种负载均衡方案较简单，缺点如下： 浏览器需两次请求才能完成一次访问 重定向服务器本身可能会成为瓶颈 HTTP返回码302重定向，可能使搜索引擎判断SEO作弊 DNS负载均衡DNS负载均衡是使用DNS服务器对同一域名配置多条A记录，每次域名解析请求都会根据对应的负载均衡算法计算出一个不同的IP地址并返回。其结构类似HTTP负载均衡，只不过将请求步骤交给了DNS服务器。 该方法有如下优点： 负载均衡任务交给DNS服务器，较为方便。 部署在服务器上的应用不需要任何配置。 服务器可以位于互联网任何位置。 DNS支持基于地理位置的域名解析，即将根据用户所在地理位置，将域名解析成距离最近的一个服务器地址，加速用户访问。 同时该方案也存在如下缺点： DNS是多级解析的，每一级都会缓存该条域名的A记录，更新记录生效需要较长时间。 不能按照服务器的处理能力来分配负载，DNS负载均衡采用的是简单的轮询算法，因此其负载均衡的效果不太好。 为保证DNS数据即时更新，使地址能随机分配，一般需要将DNS刷新时间设置较小，但会导致DNS流量大增造成其他问题。 博客美化代码块美化自带的代码块显示没有高亮，也没有一键复制的功能。因此着手添加这两项功能。 首先注意到hexo已经内部集成了highlight.js和prismjs。"}]